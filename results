C:\Users\James\Anaconda3\python.exe C:/Users/James/PycharmProjects/FIT3036/classifier_test.py
total labels: 258
number of TYP: 124, ratio over total: (0.480620)
number of ASD: 33, ratio over total: (0.127907)
number of SLI: 101, ratio over total: (0.391473)
largest population: 124 counts
therefore the baseline accuracy expected for all estimators is (0.480620) which is equivalent to randomly labelingeverything as the largest population
training set proportions:  (73, 25, 82)
test set proportions:  (28, 8, 42)
--------------------------

Features:
0 : total words
1 : number of different words
2 : total utterances
3 : mean length of utterances
4 : average syllables per word
5 : flesch kincaid score
6 : raw verbs vs total verbs
7 : number of different pos tags
8 : number of repeated words/phrases
9 : umber of partial words
10 : number of filler words
11 : degree of conversational support
12 : prosody
13 : average clauses per sentence
14 : average left branching depth
15 : max parse tree height
16 : language model average uni-gram probability
17 : language model average bi-gram probability
18 : language model average tri-gram probability
19 : language model average 4-gram probability
--------------------------

Estimator scoring including: cross validation with stratified K-fold sampling (k = 4), mean accuracy, accuracy precision, recall and f-measure
--------------------------
Decision Tree:
Mean accuracy: 0.79
Accuracy from CV scoring: 0.77 (+/- 0.07)
             precision    recall  f1-score   support

        0.0       0.77      0.96      0.86        28
        1.0       0.56      0.62      0.59         8
        2.0       0.88      0.71      0.79        42

avg / total       0.81      0.79      0.79        78

Confusion matrix, without normalization
[[27  0  1]
 [ 0  5  3]
 [ 8  4 30]]
--------------------------

K-Nearest Neighbor:
Mean accuracy: 0.85
Accuracy from CV scoring: 0.78 (+/- 0.05)
             precision    recall  f1-score   support

        0.0       0.81      0.89      0.85        28
        1.0       0.80      0.50      0.62         8
        2.0       0.88      0.88      0.88        42

avg / total       0.85      0.85      0.84        78

Confusion matrix, without normalization
[[25  0  3]
 [ 2  4  2]
 [ 4  1 37]]
--------------------------

Gaussian Naive Bayes:
Mean accuracy: 0.83
Accuracy from CV scoring: 0.85 (+/- 0.03)
             precision    recall  f1-score   support

        0.0       0.85      0.82      0.84        28
        1.0       0.53      1.00      0.70         8
        2.0       0.94      0.81      0.87        42

avg / total       0.87      0.83      0.84        78

Confusion matrix, without normalization
[[23  3  2]
 [ 0  8  0]
 [ 4  4 34]]
--------------------------

Neural Network, Multilayer Perceptron:
Mean accuracy: 0.63
Accuracy from CV scoring: 0.85 (+/- 0.06)
             precision    recall  f1-score   support

        0.0       0.59      0.68      0.63        28
        1.0       0.44      0.50      0.47         8
        2.0       0.70      0.62      0.66        42

avg / total       0.64      0.63      0.63        78

Confusion matrix, without normalization
[[19  1  8]
 [ 1  4  3]
 [12  4 26]]
--------------------------

Support Vector Machine:
Mean accuracy: 0.86
Accuracy from CV scoring: 0.87 (+/- 0.03)
             precision    recall  f1-score   support

        0.0       0.93      0.89      0.91        28
        1.0       0.58      0.88      0.70         8
        2.0       0.90      0.83      0.86        42

avg / total       0.88      0.86      0.86        78

Confusion matrix, without normalization
[[25  0  3]
 [ 0  7  1]
 [ 2  5 35]]
--------------------------

Ensemble method, Soft Voting:
Mean accuracy: 0.83
Accuracy from CV scoring: 0.90 (+/- 0.00)
             precision    recall  f1-score   support

        0.0       0.83      0.86      0.84        28
        1.0       0.71      0.62      0.67         8
        2.0       0.86      0.86      0.86        42

avg / total       0.83      0.83      0.83        78

Confusion matrix, without normalization
[[24  1  3]
 [ 0  5  3]
 [ 5  1 36]]
--------------------------

Feature ranking:
1. feature 11: degree of conversational support (0.112443)
2. feature 5: flesch kincaid score (0.094526)
3. feature 10: number of filler words (0.082708)
4. feature 14: average left branching depth (0.077165)
5. feature 13: average clauses per sentence (0.074029)
6. feature 9: umber of partial words (0.058679)
7. feature 2: total utterances (0.055597)
8. feature 19: language model average 4-gram probability (0.054239)
9. feature 8: number of repeated words/phrases (0.047796)
10. feature 3: mean length of utterances (0.046835)
11. feature 15: max parse tree height (0.043267)
12. feature 7: number of different pos tags (0.037661)
13. feature 4: average syllables per word (0.037481)
14. feature 17: language model average bi-gram probability (0.035573)
15. feature 1: number of different words (0.030922)
16. feature 6: raw verbs vs total verbs (0.027695)
17. feature 0: total words (0.023442)
18. feature 18: language model average tri-gram probability (0.020959)
19. feature 12: prosody (0.020403)
20. feature 16: language model average uni-gram probability (0.018581)
--------------------------

Retraining estimators with extracted features only:
Estimator scoring including: cross validation with stratified K-fold sampling (k = 4), mean accuracy, accuracy precision, recall and f-measure
--------------------------
Decision Tree:
Mean accuracy: 0.82
Accuracy from CV scoring: 0.82 (+/- 0.06)
             precision    recall  f1-score   support

        0.0       0.83      0.89      0.86        28
        1.0       0.50      0.75      0.60         8
        2.0       0.92      0.79      0.85        42

avg / total       0.84      0.82      0.83        78

Confusion matrix, without normalization
[[25  2  1]
 [ 0  6  2]
 [ 5  4 33]]
--------------------------

K-Nearest Neighbor:
Mean accuracy: 0.87
Accuracy from CV scoring: 0.82 (+/- 0.03)
             precision    recall  f1-score   support

        0.0       0.83      0.89      0.86        28
        1.0       1.00      0.62      0.77         8
        2.0       0.88      0.90      0.89        42

avg / total       0.88      0.87      0.87        78

Confusion matrix, without normalization
[[25  0  3]
 [ 1  5  2]
 [ 4  0 38]]
--------------------------

Gaussian Naive Bayes:
Mean accuracy: 0.81
Accuracy from CV scoring: 0.83 (+/- 0.02)
             precision    recall  f1-score   support

        0.0       0.79      0.96      0.87        28
        1.0       0.53      1.00      0.70         8
        2.0       0.97      0.67      0.79        42

avg / total       0.86      0.81      0.81        78

Confusion matrix, without normalization
[[27  0  1]
 [ 0  8  0]
 [ 7  7 28]]
--------------------------

Neural Network, Multilayer Perceptron:
Mean accuracy: 0.90
Accuracy from CV scoring: 0.70 (+/- 0.21)
             precision    recall  f1-score   support

        0.0       0.87      0.93      0.90        28
        1.0       0.86      0.75      0.80         8
        2.0       0.93      0.90      0.92        42

avg / total       0.90      0.90      0.90        78

Confusion matrix, without normalization
[[26  0  2]
 [ 1  6  1]
 [ 3  1 38]]
--------------------------

Support Vector Machine:
Mean accuracy: 0.81
Accuracy from CV scoring: 0.87 (+/- 0.08)
             precision    recall  f1-score   support

        0.0       0.86      0.89      0.88        28
        1.0       0.47      1.00      0.64         8
        2.0       0.94      0.71      0.81        42

avg / total       0.86      0.81      0.82        78

Confusion matrix, without normalization
[[25  1  2]
 [ 0  8  0]
 [ 4  8 30]]
--------------------------

Ensemble method, Soft Voting:
Mean accuracy: 0.86
Accuracy from CV scoring: 0.82 (+/- 0.04)
             precision    recall  f1-score   support

        0.0       0.93      0.93      0.93        28
        1.0       0.54      0.88      0.67         8
        2.0       0.92      0.81      0.86        42

avg / total       0.88      0.86      0.87        78

Confusion matrix, without normalization
[[26  0  2]
 [ 0  7  1]
 [ 2  6 34]]
--------------------------


Classification report generated in: 23.054479598999023 seconds